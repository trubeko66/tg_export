#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ú–æ–¥—É–ª—å –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∏ –æ—Ç—á–µ—Ç–æ–≤ –¥–ª—è Telegram Channel Exporter
"""

import json
import asyncio
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict, Counter
import re
import statistics

from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.layout import Layout
from rich.live import Live
from rich.text import Text
from rich import box


@dataclass
class ChannelAnalytics:
    """–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ –∫–∞–Ω–∞–ª—É"""
    channel_name: str
    total_messages: int
    total_media_files: int
    total_size_mb: float
    avg_messages_per_day: float
    peak_hours: List[int]
    top_keywords: List[Tuple[str, int]]
    engagement_rate: float
    last_activity: Optional[datetime]
    growth_rate: float
    media_types: Dict[str, int]


@dataclass
class ExportAnalytics:
    """–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞"""
    total_channels: int
    total_messages: int
    total_media_files: int
    total_size_mb: float
    export_success_rate: float
    avg_export_time: float
    most_active_channels: List[Tuple[str, int]]
    export_errors: int
    filtered_messages: int
    last_export: Optional[datetime]


class AnalyticsEngine:
    """–î–≤–∏–∂–æ–∫ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
    
    def __init__(self, console: Console):
        self.console = console
        self.analytics_cache = {}
        self.cache_ttl = 300  # 5 –º–∏–Ω—É—Ç
        
    def analyze_channel(self, channel_dir: Path, channel_name: str) -> ChannelAnalytics:
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
            cache_key = f"channel_{channel_name}_{channel_dir.stat().st_mtime}"
            if cache_key in self.analytics_cache:
                cached_data, timestamp = self.analytics_cache[cache_key]
                if datetime.now().timestamp() - timestamp < self.cache_ttl:
                    return cached_data
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º JSON —Ñ–∞–π–ª
            json_file = channel_dir / f"{channel_name}.json"
            if not json_file.exists():
                return self._empty_analytics(channel_name)
            
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            messages = data.get('messages', [])
            if not messages:
                return self._empty_analytics(channel_name)
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            total_messages = len(messages)
            total_media_files = sum(1 for msg in messages if msg.get('media_type'))
            total_size_mb = self._calculate_media_size(channel_dir)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            dates = [datetime.fromisoformat(msg['date']) for msg in messages if msg.get('date')]
            avg_messages_per_day = self._calculate_avg_messages_per_day(dates)
            peak_hours = self._find_peak_hours(dates)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
            all_text = ' '.join(msg.get('text', '') for msg in messages if msg.get('text'))
            top_keywords = self._extract_top_keywords(all_text)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–¥–∏–∞
            media_types = self._analyze_media_types(messages)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            engagement_rate = self._calculate_engagement_rate(messages)
            growth_rate = self._calculate_growth_rate(dates)
            last_activity = max(dates) if dates else None
            
            analytics = ChannelAnalytics(
                channel_name=channel_name,
                total_messages=total_messages,
                total_media_files=total_media_files,
                total_size_mb=total_size_mb,
                avg_messages_per_day=avg_messages_per_day,
                peak_hours=peak_hours,
                top_keywords=top_keywords,
                engagement_rate=engagement_rate,
                last_activity=last_activity,
                growth_rate=growth_rate,
                media_types=media_types
            )
            
            # –ö–µ—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.analytics_cache[cache_key] = (analytics, datetime.now().timestamp())
            
            return analytics
            
        except Exception as e:
            self.console.print(f"[red]–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–Ω–∞–ª–∞ {channel_name}: {e}[/red]")
            return self._empty_analytics(channel_name)
    
    def analyze_export_stats(self, channels: List[Any], stats: Any) -> ExportAnalytics:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–Ω–∞–ª—ã
            channel_activity = []
            total_messages = 0
            total_media = 0
            total_size = 0.0
            
            for channel in channels:
                if hasattr(channel, 'total_messages') and channel.total_messages > 0:
                    channel_activity.append((channel.title, channel.total_messages))
                    total_messages += channel.total_messages
                    total_media += getattr(channel, 'media_count', 0)
                    total_size += getattr(channel, 'media_size_mb', 0.0)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
            most_active_channels = sorted(channel_activity, key=lambda x: x[1], reverse=True)[:10]
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            export_success_rate = 100.0 - (stats.export_errors / max(1, len(channels)) * 100)
            avg_export_time = getattr(stats, 'avg_export_time', 0.0)
            
            return ExportAnalytics(
                total_channels=len(channels),
                total_messages=total_messages,
                total_media_files=total_media,
                total_size_mb=total_size,
                export_success_rate=export_success_rate,
                avg_export_time=avg_export_time,
                most_active_channels=most_active_channels,
                export_errors=stats.export_errors,
                filtered_messages=stats.filtered_messages,
                last_export=datetime.now() if stats.last_export_time else None
            )
            
        except Exception as e:
            self.console.print(f"[red]–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}[/red]")
            return self._empty_export_analytics()
    
    def _empty_analytics(self, channel_name: str) -> ChannelAnalytics:
        """–ü—É—Å—Ç–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–ª—è –∫–∞–Ω–∞–ª–∞"""
        return ChannelAnalytics(
            channel_name=channel_name,
            total_messages=0,
            total_media_files=0,
            total_size_mb=0.0,
            avg_messages_per_day=0.0,
            peak_hours=[],
            top_keywords=[],
            engagement_rate=0.0,
            last_activity=None,
            growth_rate=0.0,
            media_types={}
        )
    
    def _empty_export_analytics(self) -> ExportAnalytics:
        """–ü—É—Å—Ç–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        return ExportAnalytics(
            total_channels=0,
            total_messages=0,
            total_media_files=0,
            total_size_mb=0.0,
            export_success_rate=0.0,
            avg_export_time=0.0,
            most_active_channels=[],
            export_errors=0,
            filtered_messages=0,
            last_export=None
        )
    
    def _calculate_media_size(self, channel_dir: Path) -> float:
        """–ü–æ–¥—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤"""
        try:
            media_dir = channel_dir / "media"
            if not media_dir.exists():
                return 0.0
            
            total_size = 0
            for file_path in media_dir.iterdir():
                if file_path.is_file():
                    total_size += file_path.stat().st_size
            
            return total_size / (1024 * 1024)  # –í –ú–ë
        except Exception:
            return 0.0
    
    def _calculate_avg_messages_per_day(self, dates: List[datetime]) -> float:
        """–ü–æ–¥—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–µ–Ω—å"""
        if not dates:
            return 0.0
        
        dates.sort()
        if len(dates) < 2:
            return len(dates)
        
        time_span = (dates[-1] - dates[0]).days
        if time_span == 0:
            return len(dates)
        
        return len(dates) / time_span
    
    def _find_peak_hours(self, dates: List[datetime]) -> List[int]:
        """–ü–æ–∏—Å–∫ –ø–∏–∫–æ–≤—ã—Ö —á–∞—Å–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        if not dates:
            return []
        
        hour_counts = Counter(date.hour for date in dates)
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-3 —á–∞—Å–∞
        return [hour for hour, _ in hour_counts.most_common(3)]
    
    def _extract_top_keywords(self, text: str) -> List[Tuple[str, int]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–ø-–∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
        if not text:
            return []
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞
        clean_text = re.sub(r'[^\w\s]', ' ', text.lower())
        words = [word for word in clean_text.split() if len(word) > 3]
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
        stop_words = {
            '—ç—Ç–æ', '—á—Ç–æ', '–∫–∞–∫', '–¥–ª—è', '–∏–ª–∏', '–Ω–æ', '–µ—Å–ª–∏', '–∫–æ–≥–¥–∞', '–≥–¥–µ', '–ø–æ—á–µ–º—É',
            'the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'can', 'had', 'her', 'was', 'one', 'our', 'out', 'day', 'get', 'has', 'him', 'his', 'how', 'its', 'may', 'new', 'now', 'old', 'see', 'two', 'way', 'who', 'boy', 'did', 'man', 'men', 'put', 'say', 'she', 'too', 'use'
        }
        
        filtered_words = [word for word in words if word not in stop_words]
        word_counts = Counter(filtered_words)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-10 —Å–ª–æ–≤
        return word_counts.most_common(10)
    
    def _analyze_media_types(self, messages: List[Dict]) -> Dict[str, int]:
        """–ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤"""
        media_types = Counter()
        for msg in messages:
            media_type = msg.get('media_type')
            if media_type:
                media_types[media_type] += 1
        
        return dict(media_types)
    
    def _calculate_engagement_rate(self, messages: List[Dict]) -> float:
        """–ü–æ–¥—Å—á–µ—Ç —É—Ä–æ–≤–Ω—è –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏"""
        if not messages:
            return 0.0
        
        total_engagement = 0
        for msg in messages:
            views = msg.get('views', 0)
            forwards = msg.get('forwards', 0)
            replies = msg.get('replies', 0)
            total_engagement += views + forwards * 2 + replies * 3
        
        return total_engagement / len(messages)
    
    def _calculate_growth_rate(self, dates: List[datetime]) -> float:
        """–ü–æ–¥—Å—á–µ—Ç —Ç–µ–º–ø–∞ —Ä–æ—Å—Ç–∞"""
        if len(dates) < 2:
            return 0.0
        
        dates.sort()
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–µ—Ä–∏–æ–¥—ã –ø–æ –º–µ—Å—è—Ü–∞–º
        monthly_counts = defaultdict(int)
        for date in dates:
            month_key = f"{date.year}-{date.month:02d}"
            monthly_counts[month_key] += 1
        
        if len(monthly_counts) < 2:
            return 0.0
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π —Ä–æ—Å—Ç
        counts = list(monthly_counts.values())
        growth_rates = []
        for i in range(1, len(counts)):
            if counts[i-1] > 0:
                growth_rate = (counts[i] - counts[i-1]) / counts[i-1] * 100
                growth_rates.append(growth_rate)
        
        return statistics.mean(growth_rates) if growth_rates else 0.0


class AnalyticsReporter:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤"""
    
    def __init__(self, console: Console):
        self.console = console
        self.analytics_engine = AnalyticsEngine(console)
    
    def generate_channel_report(self, channel_dir: Path, channel_name: str) -> Panel:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ –∫–∞–Ω–∞–ª—É"""
        analytics = self.analytics_engine.analyze_channel(channel_dir, channel_name)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π
        table = Table(title=f"–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫–∞–Ω–∞–ª–∞: {channel_name}", box=box.ROUNDED)
        table.add_column("–ú–µ—Ç—Ä–∏–∫–∞", style="cyan")
        table.add_column("–ó–Ω–∞—á–µ–Ω–∏–µ", style="green")
        
        table.add_row("–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π", f"{analytics.total_messages:,}")
        table.add_row("–ú–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤", f"{analytics.total_media_files:,}")
        table.add_row("–†–∞–∑–º–µ—Ä –º–µ–¥–∏–∞", f"{analytics.total_size_mb:.1f} –ú–ë")
        table.add_row("–°–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–µ–Ω—å", f"{analytics.avg_messages_per_day:.1f}")
        table.add_row("–£—Ä–æ–≤–µ–Ω—å –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏", f"{analytics.engagement_rate:.1f}")
        table.add_row("–¢–µ–º–ø —Ä–æ—Å—Ç–∞", f"{analytics.growth_rate:.1f}%")
        
        if analytics.peak_hours:
            peak_hours_str = ", ".join(map(str, analytics.peak_hours))
            table.add_row("–ü–∏–∫–æ–≤—ã–µ —á–∞—Å—ã", f"{peak_hours_str}:00")
        
        if analytics.last_activity:
            table.add_row("–ü–æ—Å–ª–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å", analytics.last_activity.strftime("%Y-%m-%d %H:%M"))
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ø-–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        if analytics.top_keywords:
            keywords_text = ", ".join([f"{word} ({count})" for word, count in analytics.top_keywords[:5]])
            table.add_row("–¢–æ–ø-—Å–ª–æ–≤–∞", keywords_text)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏–ø—ã –º–µ–¥–∏–∞
        if analytics.media_types:
            media_text = ", ".join([f"{type_name} ({count})" for type_name, count in analytics.media_types.items()])
            table.add_row("–¢–∏–ø—ã –º–µ–¥–∏–∞", media_text)
        
        return Panel(table, title="üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫–∞–Ω–∞–ª–∞", border_style="blue")
    
    def generate_export_report(self, channels: List[Any], stats: Any) -> Panel:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ —ç–∫—Å–ø–æ—Ä—Ç—É"""
        analytics = self.analytics_engine.analyze_export_stats(channels, stats)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        table = Table(title="–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞", box=box.ROUNDED)
        table.add_column("–ú–µ—Ç—Ä–∏–∫–∞", style="cyan")
        table.add_column("–ó–Ω–∞—á–µ–Ω–∏–µ", style="green")
        
        table.add_row("–í—Å–µ–≥–æ –∫–∞–Ω–∞–ª–æ–≤", f"{analytics.total_channels:,}")
        table.add_row("–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π", f"{analytics.total_messages:,}")
        table.add_row("–ú–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤", f"{analytics.total_media_files:,}")
        table.add_row("–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä", f"{analytics.total_size_mb:.1f} –ú–ë")
        table.add_row("–£—Å–ø–µ—à–Ω–æ—Å—Ç—å —ç–∫—Å–ø–æ—Ä—Ç–∞", f"{analytics.export_success_rate:.1f}%")
        table.add_row("–û—à–∏–±–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞", f"{analytics.export_errors:,}")
        table.add_row("–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ", f"{analytics.filtered_messages:,}")
        
        if analytics.last_export:
            table.add_row("–ü–æ—Å–ª–µ–¥–Ω–∏–π —ç–∫—Å–ø–æ—Ä—Ç", analytics.last_export.strftime("%Y-%m-%d %H:%M"))
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —Å–∞–º—ã–º–∏ –∞–∫—Ç–∏–≤–Ω—ã–º–∏ –∫–∞–Ω–∞–ª–∞–º–∏
        if analytics.most_active_channels:
            active_table = Table(title="–°–∞–º—ã–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∫–∞–Ω–∞–ª—ã", box=box.ROUNDED)
            active_table.add_column("–ö–∞–Ω–∞–ª", style="cyan")
            active_table.add_column("–°–æ–æ–±—â–µ–Ω–∏–π", style="green", justify="right")
            
            for channel_name, message_count in analytics.most_active_channels:
                active_table.add_row(channel_name, f"{message_count:,}")
        
            # –°–æ–∑–¥–∞–µ–º Layout –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü
            layout = Layout()
            layout.split_column(
                Layout(table, name="main_stats"),
                Layout(active_table, name="active_channels")
            )
            
            return Panel(
                layout,
                title="üìà –û—Ç—á–µ—Ç –ø–æ —ç–∫—Å–ø–æ—Ä—Ç—É",
                border_style="green"
            )
        
        return Panel(table, title="üìà –û—Ç—á–µ—Ç –ø–æ —ç–∫—Å–ø–æ—Ä—Ç—É", border_style="green")
    
    def generate_comparison_report(self, channels_data: List[Tuple[Path, str]]) -> Panel:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        if not channels_data:
            return Panel("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è", title="üìä –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –∫–∞–Ω–∞–ª—ã
        all_analytics = []
        for channel_dir, channel_name in channels_data:
            analytics = self.analytics_engine.analyze_channel(channel_dir, channel_name)
            all_analytics.append(analytics)
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        table = Table(title="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–æ–≤", box=box.ROUNDED)
        table.add_column("–ö–∞–Ω–∞–ª", style="cyan")
        table.add_column("–°–æ–æ–±—â–µ–Ω–∏–π", style="green", justify="right")
        table.add_column("–ú–µ–¥–∏–∞", style="yellow", justify="right")
        table.add_column("–†–∞–∑–º–µ—Ä (–ú–ë)", style="blue", justify="right")
        table.add_column("–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å/–¥–µ–Ω—å", style="magenta", justify="right")
        table.add_column("–í–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å", style="red", justify="right")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–æ–æ–±—â–µ–Ω–∏–π
        all_analytics.sort(key=lambda x: x.total_messages, reverse=True)
        
        for analytics in all_analytics:
            table.add_row(
                analytics.channel_name,
                f"{analytics.total_messages:,}",
                f"{analytics.total_media_files:,}",
                f"{analytics.total_size_mb:.1f}",
                f"{analytics.avg_messages_per_day:.1f}",
                f"{analytics.engagement_rate:.1f}"
            )
        
        return Panel(table, title="üìä –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç", border_style="yellow")
    
    def export_analytics_to_json(self, channels_data: List[Tuple[Path, str]], output_file: Path):
        """–≠–∫—Å–ø–æ—Ä—Ç –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –≤ JSON"""
        try:
            analytics_data = {
                "export_timestamp": datetime.now().isoformat(),
                "channels": []
            }
            
            for channel_dir, channel_name in channels_data:
                analytics = self.analytics_engine.analyze_channel(channel_dir, channel_name)
                analytics_data["channels"].append(asdict(analytics))
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(analytics_data, f, ensure_ascii=False, indent=2, default=str)
            
            self.console.print(f"[green]–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ {output_file}[/green]")
            
        except Exception as e:
            self.console.print(f"[red]–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}[/red]")
    
    def export_analytics_to_csv(self, channels_data: List[Tuple[Path, str]], output_file: Path):
        """–≠–∫—Å–ø–æ—Ä—Ç –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –≤ CSV"""
        try:
            import csv
            
            with open(output_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                
                # –ó–∞–≥–æ–ª–æ–≤–∫–∏
                writer.writerow([
                    'Channel', 'Total Messages', 'Media Files', 'Size MB',
                    'Messages per Day', 'Engagement Rate', 'Growth Rate %',
                    'Peak Hours', 'Top Keywords', 'Media Types', 'Last Activity'
                ])
                
                # –î–∞–Ω–Ω—ã–µ
                for channel_dir, channel_name in channels_data:
                    analytics = self.analytics_engine.analyze_channel(channel_dir, channel_name)
                    
                    peak_hours = ", ".join(map(str, analytics.peak_hours)) if analytics.peak_hours else ""
                    top_keywords = ", ".join([f"{word}({count})" for word, count in analytics.top_keywords[:5]])
                    media_types = ", ".join([f"{type_name}({count})" for type_name, count in analytics.media_types.items()])
                    last_activity = analytics.last_activity.strftime("%Y-%m-%d %H:%M") if analytics.last_activity else ""
                    
                    writer.writerow([
                        analytics.channel_name,
                        analytics.total_messages,
                        analytics.total_media_files,
                        f"{analytics.total_size_mb:.1f}",
                        f"{analytics.avg_messages_per_day:.1f}",
                        f"{analytics.engagement_rate:.1f}",
                        f"{analytics.growth_rate:.1f}",
                        peak_hours,
                        top_keywords,
                        media_types,
                        last_activity
                    ])
            
            self.console.print(f"[green]–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ {output_file}[/green]")
            
        except Exception as e:
            self.console.print(f"[red]–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –≤ CSV: {e}[/red]")
